# Mastering the Fundamentals of AI and Machine Learning  
*By Rob Barton and Jerome Henry*

Welcome to the official repository for **"Mastering the Fundamentals of AI and Machine Learning"** â€” a practical, example-driven course designed to introduce core concepts in artificial intelligence and machine learning. This course is ideal for IT professionals, engineers, and anyone looking to build a solid foundation in AI.

---

## ðŸ§  Course Overview

This course is structured around eight core modules, each offering a focused dive into a specific area of AI/ML:

### ðŸ“š Course Outline

**Section 1: Key Concepts of AI and Machine Learning** *(Rob Barton)*  
- History and family tree of AI  
- Training vs. inference  
- Parameters vs. hyperparameters  
- The AI pipeline  

**Section 2: Unsupervised Learning** *(Jerome Henry)*  
- K-Means and DBSCAN  
- Dimensionality reduction with PCA and t-SNE  

**Section 3: Supervised Learning Part 1 â€“ Prediction** *(Rob Barton)*  
- Linear regression fundamentals  
- Cost functions and gradient descent  

**Section 4: Supervised Learning Part 2 â€“ Classification** *(Rob Barton)*  
- Logistic regression and the sigmoid function  

**Section 5: Decision Trees** *(Jerome Henry)*  
- Decision trees and random forests  

**Section 6: Reinforcement Learning** *(Rob Barton)*  
- Trial-and-error learning, Q-Learning, Deep Q-Learning  

**Section 7: Neural Networks & Deep Learning** *(Jerome Henry)*  
- Artificial neural networks, activation functions, ANN families  

**Section 8: Generative AI and Large Language Models (LLMs)** *(Jerome Henry)*  
- Language modeling, transformers, and "Attention is All You Need"

---

## ðŸ“‚ Repository Structure

The repository is organized into sections that correspond to the course modules, with additional supporting files:

### Course Sections
- `Section_1_Key_Concepts/` - Includes examples of supervised learning and Gradient Descent
- `Section_2_Unsupervised_Learning/` - Resources for clustering (K-Means, DBSCAN) and dimensionality reduction techniques
- `Section_3_Linear_Regression/` - Contains materials for supervised learning with linear regression
- `Section_4_Classification - Logistic Regression/` - Materials for classification using logistic regression
- `Section_6_Reinforcement_Learning/` - Resources for reinforcement learning concepts and examples
- `Section_5_Decision_Tree_Example.ipynb` - A comprehensive Jupyter notebook demonstrating decision trees
- `Section_7_CNN_Example.ipynb` - Example notebook for convolutional neural networks

### Supporting Files
- `requirements.txt` - Lists all Python package dependencies
- `venv_mastering_AI/` - Virtual environment directory (not tracked in git)
- `.gitignore` - Specifies files and directories to be ignored by git

Each section directory typically contains:
- Python scripts (`.py`) and Jupyter notebooks (`.ipynb`) with working examples
- Data files used in the examples (where applicable)
- README files with section-specific instructions
- Visualizations and demos
- Additional explanatory materials

Note: Some sections may be added or updated as the course progresses.

---

## âœ… Prerequisites

- Python 3.9+
- Virtual environment recommended
- Familiarity with basic programming concepts

---

## ðŸš€ Getting Started

1. Clone the repository:
   git clone https://github.com/robbarto2/Oreilly-Mastering-AI-Fundamentals.git
   cd Oreilly-Mastering-AI-Fundamentals

2. Create and activate a virtual environment:
    python -m venv venv
    source venv/bin/activate  # or venv\Scripts\activate on Windows

3. Install dependencies:
    pip install -r requirements.txt

4. Run Jupyter notebooks or Python files for each section.

Authors: 
Rob Barton â€“ Distinguished Engineer, AI & Networking

Jerome Henry â€“ Distinguished Engineer, Wireless & AI




